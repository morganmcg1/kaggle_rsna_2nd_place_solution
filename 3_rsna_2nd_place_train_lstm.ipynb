{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook breaks down the code to train the second part of the model, the LSTM, based the code from the [2nd place repo here](https://github.com/darraghdog/rsna/blob/master/scripts/trainlstm.py)\n",
    "\n",
    "### Main Observations\n",
    "I really enjoyed taking a look under the hood of this LSTM training script. The main thing that stood out for me was the need **to be very careful when handling the data with the custom Dataset and Collate Function**. Making sure to keep the correct sequence of images when processing the data and feeding it to the model was the goal here.\n",
    "\n",
    "Also dealing with batches containing odd sequence lengths was an issue that was nicely dealt with. The LSTM model is surprisingly easy to understand, yet clearly very effective.\n",
    "\n",
    "### Loading already trained embeddings\n",
    "\n",
    "The winners also enabled us to download the 2nd Place Stage 1 train and validation embeddings and the Stage 2 test embeddings from their trained Resnext101 model. \n",
    "\n",
    "As described in their repo, the following code will download the Stage 1 train, validation and test (stage 1) embeddings. The `gdown` package is used as the file size on the google drive is quite large (16gb):\n",
    "\n",
    "`pip install gdown\n",
    "gdown https://drive.google.com/uc?id=13hqPFdCjoMxtAwF863J3Dk33TcBN_wie -O resnext101v12fold1.tar.gz\n",
    "gunzip resnext101v12fold1.tar.gz\n",
    "tar -xvf resnext101v12fold1.tar`\n",
    "\n",
    "The Stage 2 test embeddings can then be downloaded: \n",
    "\n",
    "`wget gdown https://drive.google.com/uc?id=1YxCJ0mWIYXfYLN15DPpQ6OLSt4Y54Hp0`\n",
    "\n",
    "### Core Modelling Parameters\n",
    "- Model : Custom LSTM, from stage 1 Kaggle Toxic comp\n",
    "- Epochs : 10\n",
    "- Folds : 2, (this notebook doesn't implement folds, the 2nd place solution only got the chance to train for 2 folds but wanted to train for more)\n",
    "- Optimizer : Adam\n",
    "- Batch Size : 4\n",
    "\n",
    "### This Notebook\n",
    "The initial cells are a little messy are they are a copy and paste from the python script and I don't have a huge amount of time to reformat them to be more suitable for Jupyter.\n",
    "\n",
    "Also, this notebook is a modification from the original training script in the following ways:\n",
    "- The Stage-1 train and validation datasets were used as they were available to download from the 2nd place solution repo\n",
    "- The Stage-2 test dataset was used, in order to submit a prediction to Kaggle\n",
    "- Folds were not used as I just wanted to get a demo working, and not spend gpu time replicating the initial score\n",
    "- You might have to tweak the directory settings to match your own folder names/structure\n",
    "- The section around processing and loading the saved embeddings looks different to the original script, but the outcome is the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv, gzip, os, sys, gc\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import optparse\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import log_loss\n",
    "import ast\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import uniform_filter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex.fp16_utils import *\n",
    "from apex import amp, optimizers\n",
    "from apex.multi_tensor_apply import multi_tensor_applier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep scrolling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print info about environments\n",
    "parser = optparse.OptionParser()\n",
    "parser.add_option('-s', '--seed', action=\"store\", dest=\"seed\", help=\"model seed\", default=\"1234\")\n",
    "parser.add_option('-o', '--fold', action=\"store\", dest=\"fold\", help=\"Fold for split\", default=\"0\")\n",
    "parser.add_option('-p', '--nbags', action=\"store\", dest=\"nbags\", help=\"Number of bags for averaging\", default=\"4\")\n",
    "parser.add_option('-e', '--epochs', action=\"store\", dest=\"epochs\", help=\"epochs\", default=\"10\")\n",
    "parser.add_option('-b', '--batchsize', action=\"store\", dest=\"batchsize\", help=\"batch size\", default=\"4\")\n",
    "parser.add_option('-r', '--rootpath', action=\"store\", dest=\"rootpath\", help=\"root directory\", default=\"\")\n",
    "parser.add_option('-i', '--imgpath', action=\"store\", dest=\"imgpath\", help=\"root directory\", default=\"data/mount/512X512X6/\")\n",
    "parser.add_option('-w', '--workpath', action=\"store\", dest=\"workpath\", help=\"Working path\", default=\"weights/\")\n",
    "parser.add_option('-f', '--weightsname', action=\"store\", dest=\"weightsname\", help=\"Weights file name\", default=\"pytorch_model.bin\")\n",
    "parser.add_option('-l', '--lr', action=\"store\", dest=\"lr\", help=\"learning rate\", default=\"0.00005\")\n",
    "parser.add_option('-g', '--logmsg', action=\"store\", dest=\"logmsg\", help=\"root directory\", default=\"Recursion-pytorch\")\n",
    "parser.add_option('-c', '--size', action=\"store\", dest=\"size\", help=\"model size\", default=\"512\")\n",
    "parser.add_option('-a', '--globalepoch', action=\"store\", dest=\"globalepoch\", help=\"root directory\", default=\"3\")\n",
    "parser.add_option('-n', '--loadcsv', action=\"store\", dest=\"loadcsv\", help=\"Convert csv embeddings to numpy\", default=\"F\")\n",
    "parser.add_option('-j', '--lstm_units', action=\"store\", dest=\"lstm_units\", help=\"Lstm units\", default=\"128\")\n",
    "parser.add_option('-d', '--dropout', action=\"store\", dest=\"dropout\", help=\"LSTM input spatial dropout\", default=\"0.3\")\n",
    "parser.add_option('-z', '--decay', action=\"store\", dest=\"decay\", help=\"Weight Decay\", default=\"0.0\")\n",
    "parser.add_option('-m', '--lrgamma', action=\"store\", dest=\"lrgamma\", help=\"Scheduler Learning Rate Gamma\", default=\"1.0\")\n",
    "parser.add_option('-k', '--ttahflip', action=\"store\", dest=\"ttahflip\", help=\"Bag with horizontal flip on and off\", default=\"F\")\n",
    "parser.add_option('-q', '--ttatranspose', action=\"store\", dest=\"ttatranspose\", help=\"Bag with horizontal flip on and off\", default=\"F\")\n",
    "parser.add_option('-x', '--datapath', action=\"store\", dest=\"datapath\", help=\"Data path\", default=\"data\")\n",
    "\n",
    "options, args = parser.parse_args()\n",
    "package_dir = options.rootpath\n",
    "sys.path.append(package_dir)\n",
    "sys.path.insert(0, 'scripts')\n",
    "from logs import get_logger\n",
    "from utils import dumpobj, loadobj, GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep scrolling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-29 12:46:44,515 - Recursion-pytorch - INFO - Cuda set up : time 12:46:44.515726\n",
      "2020-01-29 12:46:44,524 - Recursion-pytorch - INFO - Device : GeForce RTX 2080 Ti\n",
      "2020-01-29 12:46:44,525 - Recursion-pytorch - INFO - Cuda available : True\n",
      "2020-01-29 12:46:44,526 - Recursion-pytorch - INFO - Cuda n_gpus : 1\n",
      "2020-01-29 12:46:44,526 - Recursion-pytorch - INFO - Load params : time 12:46:44.526832\n",
      "2020-01-29 12:46:44,527 - Recursion-pytorch - INFO - seed                1234\n",
      "2020-01-29 12:46:44,527 - Recursion-pytorch - INFO - fold                0\n",
      "2020-01-29 12:46:44,528 - Recursion-pytorch - INFO - nbags               4\n",
      "2020-01-29 12:46:44,528 - Recursion-pytorch - INFO - epochs              10\n",
      "2020-01-29 12:46:44,529 - Recursion-pytorch - INFO - batchsize           4\n",
      "2020-01-29 12:46:44,529 - Recursion-pytorch - INFO - rootpath            \n",
      "2020-01-29 12:46:44,530 - Recursion-pytorch - INFO - imgpath             data/mount/512X512X6/\n",
      "2020-01-29 12:46:44,530 - Recursion-pytorch - INFO - workpath            weights/\n",
      "2020-01-29 12:46:44,531 - Recursion-pytorch - INFO - weightsname         /home/morgan/.local/share/jupyter/runtime/kernel-413dd5aa-64c8-4380-9765-d9843833952f.json\n",
      "2020-01-29 12:46:44,531 - Recursion-pytorch - INFO - lr                  0.00005\n",
      "2020-01-29 12:46:44,532 - Recursion-pytorch - INFO - logmsg              Recursion-pytorch\n",
      "2020-01-29 12:46:44,532 - Recursion-pytorch - INFO - size                512\n",
      "2020-01-29 12:46:44,533 - Recursion-pytorch - INFO - globalepoch         3\n",
      "2020-01-29 12:46:44,533 - Recursion-pytorch - INFO - loadcsv             F\n",
      "2020-01-29 12:46:44,534 - Recursion-pytorch - INFO - lstm_units          128\n",
      "2020-01-29 12:46:44,534 - Recursion-pytorch - INFO - dropout             0.3\n",
      "2020-01-29 12:46:44,535 - Recursion-pytorch - INFO - decay               0.0\n",
      "2020-01-29 12:46:44,535 - Recursion-pytorch - INFO - lrgamma             1.0\n",
      "2020-01-29 12:46:44,536 - Recursion-pytorch - INFO - ttahflip            F\n",
      "2020-01-29 12:46:44,536 - Recursion-pytorch - INFO - ttatranspose        F\n",
      "2020-01-29 12:46:44,536 - Recursion-pytorch - INFO - datapath            data\n"
     ]
    }
   ],
   "source": [
    "# Print info about environments\n",
    "logger = get_logger(options.logmsg, 'INFO') # noqa\n",
    "logger.info('Cuda set up : time {}'.format(datetime.datetime.now().time()))\n",
    "\n",
    "device=torch.device('cuda')\n",
    "logger.info('Device : {}'.format(torch.cuda.get_device_name(0)))\n",
    "logger.info('Cuda available : {}'.format(torch.cuda.is_available()))\n",
    "n_gpu = torch.cuda.device_count()\n",
    "logger.info('Cuda n_gpus : {}'.format(n_gpu ))\n",
    "\n",
    "\n",
    "logger.info('Load params : time {}'.format(datetime.datetime.now().time()))\n",
    "for (k,v) in options.__dict__.items():\n",
    "    logger.info('{}{}'.format(k.ljust(20), v))\n",
    "\n",
    "WDIR = 'resnext101v01'\n",
    "GEPOCH=0\n",
    "epochs = 12\n",
    "fold = 0\n",
    "lr = 0.00001\n",
    "batchsize = 4\n",
    "workpath = f'scripts/{WDIR}'\n",
    "ttahflip = 'T'\n",
    "ttatranspose = 'T'\n",
    "lrgamma = 0.95\n",
    "nbags = 12\n",
    "globalepoch = f'{GEPOCH}'\n",
    "loadcsv = 'F'\n",
    "lstm_units = 2048\n",
    "    \n",
    "SEED = int(options.seed)\n",
    "SIZE = 408 # int(options.size)\n",
    "EPOCHS = int(options.epochs)\n",
    "GLOBALEPOCH= globalepoch #int(options.globalepoch)\n",
    "n_epochs = EPOCHS \n",
    "lr=float(options.lr)\n",
    "#lrgamma=float(options.lrgamma)\n",
    "DECAY=float(options.decay)\n",
    "batch_size = batchsize  #int(options.batchsize)\n",
    "ROOT = options.rootpath\n",
    "path_data = os.path.join(ROOT, options.datapath)\n",
    "path_img = os.path.join(ROOT, options.imgpath)\n",
    "WORK_DIR = os.path.join(ROOT, options.workpath)\n",
    "path_emb = os.path.join(ROOT, options.workpath)\n",
    "WEIGHTS_NAME = options.weightsname\n",
    "FOLD = 0   #int(options.fold)\n",
    "LOADCSV= options.loadcsv=='T'\n",
    "LSTM_UNITS=2048   #int(options.lstm_units)\n",
    "#nbags=int(options.nbags)\n",
    "DROPOUT=float(options.dropout)\n",
    "TTAHFLIP= 'T'  #'T' if options.ttahflip=='T' else ''\n",
    "TTATRANSPOSE='P' if options.ttatranspose=='T' else ''\n",
    "\n",
    "n_classes = 6\n",
    "label_cols = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "logmsg = f'Rsna-lstm-{GEPOCH}-{FOLD}-fp16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntracranialDataset(Dataset):\n",
    "    def __init__(self, df, mat, labels=label_cols):\n",
    "        self.data = df\n",
    "        self.mat = mat\n",
    "        #print(self.mat.shape)\n",
    "        self.labels = labels\n",
    "        self.patients = df.SliceID.unique()\n",
    "        self.data = self.data.set_index('SliceID')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get the PatientID from the given index\n",
    "        patidx = self.patients[idx]\n",
    "        \n",
    "        # For a particular PatientID, sort the values according to the seq key\n",
    "        # Wrap the argument to .loc in a list to ensure a dataframe is returned every time\n",
    "        patdf = self.data.loc[[patidx]].sort_values('seq')            \n",
    "            \n",
    "        # Select the embedding index values from the particular Patient Dataframe\n",
    "        # and index into the dataset .mat with those indices\n",
    "        patemb = self.mat[patdf['embidx'].values]\n",
    "\n",
    "        # Feed in the embeddings in sequence on key - Patient, Study and Series - \n",
    "        # also concat on the deltas between current and previous/next embeddings ( and ) \n",
    "        # to give the model knowledge of changes around the image.\n",
    "        \n",
    "        # This will mean that every item from the Dataset will return 3 embeddings:\n",
    "        #   -  The patient's embedding for that image (\"patemb\")\n",
    "        #   -  The difference between an embedding and its previous embedding(\"patdeltalag\")\n",
    "        #   -  The difference between an embedding and its previous embedding(\"patdeltalead\")\n",
    "        \n",
    "        patdeltalag  = np.zeros(patemb.shape)\n",
    "        patdeltalead = np.zeros(patemb.shape)\n",
    "        patdeltalag [1:] = patemb[1:]-patemb[:-1]   # e.g. patemb.shape = (36, 2048) , patemb[1:].shape = (35, 2048)\n",
    "        patdeltalead[:-1] = patemb[:-1]-patemb[1:]\n",
    "\n",
    "        # The 3 embeddings are concatted together going from 3 x (36, 2048) to (36, 6144)\n",
    "        patemb = np.concatenate((patemb, patdeltalag, patdeltalead), -1)\n",
    "        \n",
    "        ids = torch.tensor(patdf['embidx'].values)\n",
    "\n",
    "        if self.labels:\n",
    "            labels = torch.tensor(patdf[label_cols].values)\n",
    "            return {'emb': patemb, 'embidx' : ids, 'labels': labels}    \n",
    "        else:      \n",
    "            return {'emb': patemb, 'embidx' : ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Metadata DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SliceID \n",
    "based on ['PatientID', 'SeriesInstanceUID', 'StudyInstanceUID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-29 12:46:44,549 - Recursion-pytorch - INFO - Cuda set up : time 12:46:44.549043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752803 121232\n"
     ]
    }
   ],
   "source": [
    "from random import sample \n",
    "\n",
    "# Print info about environments\n",
    "logger.info('Cuda set up : time {}'.format(datetime.datetime.now().time()))\n",
    "\n",
    "# Get image sequences\n",
    "trnmdf = pd.read_csv(os.path.join(path_data, 'rsna_darraghdog/darraghdog_train_metadata.csv'))\n",
    "#trnmdf.Image = 'train_' + trnmdf.Image\n",
    "tstmdf = pd.read_csv(os.path.join(path_data, 'rsna_darraghdog/darraghdog_test_metadata.csv'))\n",
    "#tstmdf.Image = 'test_' + tstmdf.Image\n",
    "\n",
    "trnmdf['SliceID'] = trnmdf[['PatientID', 'SeriesInstanceUID', 'StudyInstanceUID']].apply(lambda x: '{}__{}__{}'.format(*x.tolist()), 1)\n",
    "tstmdf['SliceID'] = tstmdf[['PatientID', 'SeriesInstanceUID', 'StudyInstanceUID']].apply(lambda x: '{}__{}__{}'.format(*x.tolist()), 1)\n",
    "\n",
    "print(len(trnmdf), len(tstmdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sequence Count\n",
    "- Generate Sequence numbers for each series of images based on ['SliceID', 'ImagePos1', 'ImagePos2', 'ImagePos3']\n",
    "- Reduce num of colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752803 121232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>SliceID</th>\n",
       "      <th>Image</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>train_ID_45785016b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>train_ID_37f32aed2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>train_ID_1b9de2922</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>train_ID_d61a6a7b9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>train_ID_406c82112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PatientID                                    SliceID               Image  \\\n",
       "0  ID_0002cd41  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4  train_ID_45785016b   \n",
       "1  ID_0002cd41  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4  train_ID_37f32aed2   \n",
       "2  ID_0002cd41  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4  train_ID_1b9de2922   \n",
       "3  ID_0002cd41  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4  train_ID_d61a6a7b9   \n",
       "4  ID_0002cd41  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4  train_ID_406c82112   \n",
       "\n",
       "   seq  \n",
       "0    1  \n",
       "1    2  \n",
       "2    3  \n",
       "3    4  \n",
       "4    5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate poscols like this: ['ImagePos1', 'ImagePos2', 'ImagePos3']\n",
    "poscols = ['ImagePos{}'.format(i) for i in range(1, 4)]\n",
    "\n",
    "# Parse the ImagePositionPatient string (e.g. \"['-125.000', '-144.700', '109.750']\" ) and add each value\n",
    "# to one of 3 \"ImagePos\" columns\n",
    "# ast.literal_eval()\n",
    "#     Safely evaluate an expression node or a string containing a Python literal \n",
    "#     or container display. The string or node provided may only consist of the \n",
    "#     following Python literal structures: strings, bytes, numbers, tuples, lists, \n",
    "#     dicts, sets, booleans, and None.\n",
    "# This can be used for safely evaluating strings containing Python values from untrusted sources \n",
    "# without the need to parse the values oneself. It is not capable of evaluating arbitrarily \n",
    "# complex expressions, for example involving operators or indexing.\n",
    "\n",
    "trnmdf[poscols] = pd.DataFrame(trnmdf['ImagePositionPatient']\\\n",
    "              .apply(lambda x: list(map(float, ast.literal_eval(x)))).tolist())\n",
    "tstmdf[poscols] = pd.DataFrame(tstmdf['ImagePositionPatient']\\\n",
    "              .apply(lambda x: list(map(float, ast.literal_eval(x)))).tolist())\n",
    "\n",
    "# 1. Sort values by ['SliceID', 'ImagePos1', 'ImagePos2', 'ImagePos3']\n",
    "# 2. Only select the following columns:  [PatientID, SliceID,SOPInstanceUID,ImagePos1,ImagePos2,ImagePos3]\n",
    "# 3. Reset index\n",
    "trnmdf = trnmdf.sort_values(['SliceID']+poscols)\\\n",
    "                [['PatientID', 'SliceID', 'SOPInstanceUID']+poscols].reset_index(drop=True)\n",
    "tstmdf = tstmdf.sort_values(['SliceID']+poscols)\\\n",
    "                [['PatientID', 'SliceID', 'SOPInstanceUID']+poscols].reset_index(drop=True)\n",
    "\n",
    "# Group by the SliceID col and then do a cumulative count for each item that it is grouped by\n",
    "# Beacuse these samples have already been sorted by ['SliceID', 'ImagePos1', 'ImagePos2', 'ImagePos3']\n",
    "# this value can be inferred to the sequence order of this sequence of images\n",
    "trnmdf['seq'] = (trnmdf.groupby(['SliceID']).cumcount() + 1)\n",
    "tstmdf['seq'] = (tstmdf.groupby(['SliceID']).cumcount() + 1)\n",
    "\n",
    "# Further reduce the columns kept\n",
    "keepcols = ['PatientID', 'SliceID', 'SOPInstanceUID', 'seq']\n",
    "trnmdf = trnmdf[keepcols]\n",
    "tstmdf = tstmdf[keepcols]\n",
    "\n",
    "# rename SOPInstanceUID to Image to prepare to join to the dataframe with labels\n",
    "trnmdf.columns = tstmdf.columns = ['PatientID', 'SliceID', 'Image', 'seq']\n",
    "\n",
    "trnmdf.Image = 'train_' + trnmdf.Image\n",
    "tstmdf.Image = 'test_' + tstmdf.Image\n",
    "\n",
    "print(len(trnmdf), len(tstmdf))\n",
    "\n",
    "trnmdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_stg1_2_embs_data():\n",
    "    imgpath = 'data/rsna_darraghdog/darraghdog_proc'\n",
    "\n",
    "    stg_1_trn_loader = loadobj('weights/stg1_downloaded_embeddings_resnext101v12fold1/loader_trn_size480_fold1_ep4')\n",
    "    stg_1_val_loader = loadobj('weights/stg1_downloaded_embeddings_resnext101v12fold1/loader_val_size480_fold1_ep4')\n",
    "    \n",
    "    stg_1_trn_loader.dataset.path = imgpath\n",
    "    stg_1_val_loader.dataset.path = imgpath\n",
    "\n",
    "    stg_1_trn_df = stg_1_trn_loader.dataset.data\n",
    "    stg_1_val_df = stg_1_val_loader.dataset.data\n",
    "\n",
    "    stg_1_trn_df.Image = ['train_ID_' + x.split('_', 1)[1] for x in stg_1_trn_df.Image]\n",
    "    stg_1_val_df.Image = ['train_ID_' + x.split('_', 1)[1] for x in stg_1_val_df.Image]\n",
    "\n",
    "    # LOAD Stg2Test\n",
    "    stg_2_tst_loader = loadobj('weights/stg2tst/loader_tst2_size480_fold1_ep5')\n",
    "    stg_2_tst_loader.dataset.path = imgpath\n",
    "    stg_2_tst_df = stg_2_tst_loader.dataset.data\n",
    "    \n",
    "    return stg_1_trn_df, stg_1_val_df, stg_2_tst_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Processing\n",
    "- Load Stage 1 + 2 Datasets\n",
    "- Set the embedding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>embidx</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>fold</th>\n",
       "      <th>SliceID</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_ID_45785016b</td>\n",
       "      <td>146382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_ID_37f32aed2</td>\n",
       "      <td>117917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_ID_1b9de2922</td>\n",
       "      <td>58394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_ID_d61a6a7b9</td>\n",
       "      <td>451680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_ID_406c82112</td>\n",
       "      <td>135730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0002cd41</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0002cd41__ID_e22a5534e6__ID_66929e09d4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Image  embidx  any  epidural  intraparenchymal  \\\n",
       "0  train_ID_45785016b  146382    0         0                 0   \n",
       "1  train_ID_37f32aed2  117917    0         0                 0   \n",
       "2  train_ID_1b9de2922   58394    0         0                 0   \n",
       "3  train_ID_d61a6a7b9  451680    0         0                 0   \n",
       "4  train_ID_406c82112  135730    0         0                 0   \n",
       "\n",
       "   intraventricular  subarachnoid  subdural    PatientID  fold  \\\n",
       "0                 0             0         0  ID_0002cd41     4   \n",
       "1                 0             0         0  ID_0002cd41     4   \n",
       "2                 0             0         0  ID_0002cd41     4   \n",
       "3                 0             0         0  ID_0002cd41     4   \n",
       "4                 0             0         0  ID_0002cd41     4   \n",
       "\n",
       "                                     SliceID  seq  \n",
       "0  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4    1  \n",
       "1  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4    2  \n",
       "2  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4    3  \n",
       "3  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4    4  \n",
       "4  ID_0002cd41__ID_e22a5534e6__ID_66929e09d4    5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_stg1_embs = True\n",
    "\n",
    "if use_stg1_embs:\n",
    "    \n",
    "    # Retrieve the Stage 1 data and stage 2 test data from the saved dataloaders\n",
    "    stg_1_trn_df, stg_1_val_df, stg_2_tst_df = return_stg1_2_embs_data()\n",
    "    \n",
    "    # THE ORDER OF THE ORIGINAL TRAIN DATASET SHOULD BE PRESERVED\n",
    "    # Save the current order of the embeddings (as the loaded ones are in this order)\n",
    "    stg_1_trn_df['embidx'] = range(stg_1_trn_df.shape[0])\n",
    "    stg_1_val_df['embidx'] = range(stg_1_val_df.shape[0])\n",
    "    \n",
    "    # MERGE stg1 train and val sets\n",
    "    train = pd.concat([stg_1_trn_df, stg_1_val_df], axis=0, sort=False)\n",
    "    \n",
    "    # IMPORT STAGE 2 TRAIN (which has all labels)\n",
    "    stg2_train = pd.read_csv(os.path.join(path_data, 'rsna_darraghdog/darraghdog_train.csv.gz'))\n",
    "    stg2_test = pd.read_csv(os.path.join(path_data, 'rsna_darraghdog/darraghdog_test.csv.gz'))\n",
    "    \n",
    "    stg2_train.Image = 'train_' + stg2_train.Image\n",
    "    stg2_test.Image = 'test_' + stg2_test.Image\n",
    "    \n",
    "    # DROP the fold column as we want to use the \n",
    "    stg2_train.drop(['fold'], axis=1)\n",
    "    \n",
    "    # DROP LABEL COLS (as some are missing due to stg_1_tst_df merge) COLUMNS FROM train\n",
    "    drop_cols = label_cols.copy()\n",
    "    drop_cols.append('PatientID')\n",
    "    drop_cols.append('fold')\n",
    "    train.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # MERGE train with stg2_train\n",
    "    train = train.merge(stg2_train, on = 'Image', sort=False)\n",
    "    \n",
    "    # RENAME STAGE 2 TEST\n",
    "    test = stg2_test.copy()\n",
    "        \n",
    "    # MERGE with METADATA DF to get full picture\n",
    "    trndf = train.merge(trnmdf.drop('PatientID', 1), on = 'Image')\n",
    "    tstdf = test.merge(tstmdf, on = 'Image')\n",
    "    \n",
    "    # THE ORDER OF THE ORIGINAL TRAIN DATASET SHOULD BE PRESERVED\n",
    "    # Save the current order of the embeddings (as the loaded ones are in this order)\n",
    "    tstdf['embidx'] = range(tstdf.shape[0])\n",
    "\n",
    "    # THE ORDER OF THE ORIGINAL TRAIN DATASET SHOULD BE PRESERVED\n",
    "    \n",
    "    trndf = trndf.sort_values(['PatientID','SliceID','seq']).reset_index(drop=True)\n",
    "    tstdf = tstdf.sort_values(['PatientID','SliceID','seq']).reset_index(drop=True)\n",
    "\n",
    "trndf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val Split\n",
    "Split into Train and Val sets again, as per Stg1 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539827, 134430)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf = trndf.loc[trndf.Image.isin(stg_1_val_df.Image.values)].copy()\n",
    "trndf = trndf.loc[trndf.Image.isin(stg_1_trn_df.Image.values)].copy()\n",
    "len(trndf), len(valdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Embeddings\n",
    "- Load the Stage 1 Train + Val Embeddings and the Stage 2 Test Embeddings\n",
    "- Assuming Stage2 embeddings came from the same model as the Stage1 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-29 13:04:31,858 - Recursion-pytorch - INFO - Load embeddings...\n",
      "2020-01-29 13:05:12,360 - Recursion-pytorch - INFO - Trn shape 539827 2048\n",
      "2020-01-29 13:05:12,368 - Recursion-pytorch - INFO - Val shape 134430 2048\n",
      "2020-01-29 13:05:12,369 - Recursion-pytorch - INFO - Tst shape 121232 2048\n"
     ]
    }
   ],
   "source": [
    "def load_saved_emb(e_pth, emb_path):\n",
    "    return np.load(os.path.join(e_pth, emb_path))['arr_0']\n",
    "\n",
    "stg_1_emb_path = 'weights/stg1_downloaded_embeddings_resnext101v12fold1'\n",
    "stg_2_path_emb = 'weights/stg2tst'\n",
    "\n",
    "# Paths for the Stage 1 embeddings\n",
    "trn_emb_path = 'emb_trn_size480_fold1_ep4.npz'\n",
    "val_emb_path = 'emb_val_size480_fold1_ep4.npz'\n",
    "\n",
    "# Paths for the Stage 2 embeddings\n",
    "tst_emb_path = 'emb_tst2_size480_fold1_ep5.npz'\n",
    "\n",
    "logger.info('Load embeddings...')\n",
    "trnembls = [load_saved_emb(stg_1_emb_path, trn_emb_path)]\n",
    "valembls = [load_saved_emb(stg_1_emb_path, val_emb_path)]\n",
    "tstembls = [load_saved_emb(stg_2_path_emb, tst_emb_path)]\n",
    "\n",
    "trnemb = sum(trnembls)/len(trnembls)\n",
    "valemb = sum(valembls)/len(valembls)\n",
    "tstemb = sum(tstembls)/len(tstembls)\n",
    "\n",
    "logger.info('Trn shape {} {}'.format(*trnemb.shape))\n",
    "logger.info('Val shape {} {}'.format(*valemb.shape))\n",
    "logger.info('Tst shape {} {}'.format(*tstemb.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Function\n",
    "- Define a collate function to pass to collate_fn in the DataLoader in order to operate on the Dataset as needed\n",
    "- https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collatefn(batch):\n",
    "    maxlen = max([l['emb'].shape[0] for l in batch])\n",
    "    \n",
    "    embdim = batch[0]['emb'].shape[1]\n",
    "    withlabel = 'labels' in batch[0]\n",
    "    if withlabel:\n",
    "        labdim= batch[0]['labels'].shape[1]\n",
    "    \n",
    "    for b in batch:\n",
    "        # batch size could be (3, 40, 6144)\n",
    "        # For sequences of different length:\n",
    "        #     - padded them to same length\n",
    "        #     - made a dummy embedding of zeros\n",
    "        #     - then threw the results of this away before calculating loss and saving the predictions.\n",
    "        #\n",
    "        # \"masklen\"  :  The number of dummy image embeddings to add to make sure each dequence in the batch \n",
    "        # has the same dequence length. Calculated as the difference between:\n",
    "        #     - the number of the LONGEST sequence of embeddings\n",
    "        #       in the batch (longest seq of images from the same patient)\n",
    "        #     MINUS\n",
    "        #     - The number of image embeddings of this particular sequence\n",
    "        #\n",
    "        # A batch contains sequences of images from multiple patients. Some patients\n",
    "        # might have 28 images in their sequence, while some others might have 40. \n",
    "        # If there a patients with different numbers of images (different lengths of sequences)\n",
    "        # in a batch then these sequences won't be able to be stacked as items in a  batch must \n",
    "        # the same dimensions. \n",
    "        # This scenario is addressed by creating dummy images full of zeros and adding them to \n",
    "        # a patient's sequence of images. The number of dummy images needed is dictated by the \n",
    "        # the \"masklen\"\n",
    "        masklen = maxlen-len(b['emb'])\n",
    "        \n",
    "        # Stack a number (\"masklen\") of dummy embeddings onto the current sequence of embeddings\n",
    "        # to make sure all sequences in the batch are the same length\n",
    "        b['emb'] = np.vstack((np.zeros((masklen, embdim)), b['emb']))\n",
    "        \n",
    "        # Adjust the embedding index \"embidx\" by adding a number (\"masklen\") of -1's to it\n",
    "        # e.g. tensor([-1, -1, -1, -1])\n",
    "        b['embidx'] = torch.cat((torch.ones((masklen),dtype=torch.long)*-1, b['embidx']))\n",
    "        \n",
    "        # \"mask\" is a flag to indicate whether the embedding is a dummy or not \"array([1., 1., 1., 1.])\"\n",
    "        # Create it to be the length of the longest sequence and fill it with 1's\n",
    "        b['mask'] = np.ones((maxlen))\n",
    "        \n",
    "        # Change the first numbner (\"masklen\") of flags to have a 0 flag, meaning it is a dummy embedding\n",
    "        # This works because the dummy embeddings were inserted ahead of the real embeddings in \"b['emb']\"\n",
    "        b['mask'][:masklen] = 0.\n",
    "        if withlabel:\n",
    "            # Add dummy labels for the dummy embeddings\n",
    "            b['labels'] = np.vstack((np.zeros((maxlen-len(b['labels']), labdim)), b['labels']))\n",
    "    \n",
    "    # Expand the array dimensions to be the correct dims for the LSTM model.\n",
    "    # nn.LSTM takes inputs of shape: (batch, seq_len, input_size) when batch_first=True in the lstm definition\n",
    "    # numpy.expand_dims(a, axis)[source]\n",
    "    #     Expand the shape of an array. Insert a new axis that will appear at the axis position\n",
    "    #     in the expanded array shape.\n",
    "    #     Returns: View of a with the number of dimensions increased by one.\n",
    "    # e.g. Expands b['emb'] from (36, 6144) to (1, 36, 6144)\n",
    "    outbatch = {'emb' : torch.tensor(np.vstack([np.expand_dims(b['emb'], 0) \\\n",
    "                                                for b in batch])).float()}  \n",
    "    \n",
    "    outbatch['mask'] = torch.tensor(np.vstack([np.expand_dims(b['mask'], 0) \\\n",
    "                                                for b in batch])).float()\n",
    "    outbatch['embidx'] = torch.tensor(np.vstack([np.expand_dims(b['embidx'], 0) \\\n",
    "                                                for b in batch])).float()\n",
    "    if withlabel:\n",
    "        outbatch['labels'] = torch.tensor(np.vstack([np.expand_dims(b['labels'], 0) for b in batch])).float()\n",
    "    return outbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Create the PyTorch Datasets and Dataloaders based on loaded info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Create loaders...')\n",
    "trndataset = IntracranialDataset(trndf, trnemb, labels=True)\n",
    "valdataset = IntracranialDataset(valdf, valemb, labels=True)\n",
    "tstdataset = IntracranialDataset(tstdf, tstemb, labels=False)\n",
    "\n",
    "batch_size=4\n",
    "trnloader = DataLoader(trndataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=collatefn)\n",
    "valloader = DataLoader(valdataset, batch_size=batch_size*4, shuffle=False, num_workers=8, collate_fn=collatefn)\n",
    "tstloader = DataLoader(tstdataset, batch_size=batch_size*4, shuffle=False, num_workers=8, collate_fn=collatefn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpatialDropout not used in the final solution, leaving it in here just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpatialDropout(nn.Dropout2d):\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "#         x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "#         x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "#         x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "#         x = x.squeeze(2)  # (N, T, K)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embed_size=trnemb.shape[-1]*3, LSTM_UNITS=64, DO = 0.3):  # embed_size=trnemb.shape[-1]*3\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        # embed_size=trnemb.shape[-1]*3 because of the earlier creatiion of lagging and leading embeddings\n",
    "        # trnemb.shape) (26805, 2048)\n",
    "        # trnemb.shape[-1]) is 2048\n",
    "        #trnemb.shape[-1]*3) is 6144\n",
    "        \n",
    "        # This SpatialDropout doesn't seem to be used, commenting out\n",
    "        #self.embedding_dropout = SpatialDropout(0.0) #DO)\n",
    "        \n",
    "        # LSTM\n",
    "        #  input of shape (batch, seq_len, input_size): tensor containing the \n",
    "        #    features of the input sequence.\n",
    "        #  h_0 of shape (batch, num_layers * num_directions, hidden_size): tensor \n",
    "        #    containing the initial hidden state for each element in the batch. If \n",
    "        #    the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "        #  c_0 of shape (batch, num_layers * num_directions, hidden_size): tensor\n",
    "        \n",
    "        # Note, bidirectional=True, meaning the lstm runs through the sequence \n",
    "        # forwards and backwards, returning the SUM of each output\n",
    "        self.lstm1 = nn.LSTM(input_size=embed_size,   # 6144\n",
    "                             hidden_size=LSTM_UNITS,  # 64\n",
    "                             bidirectional=True,\n",
    "                             batch_first=True)\n",
    "        # lstm1 output size will be: torch.Size([3, 36, 4096]), when LSTM_UNITS=2048\n",
    "        # output of shape `(batch, seq_len, num_directions * hidden_size), (3, 36, 2 * 64) when LSTM_UNITS=64\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2,   # 128\n",
    "                             LSTM_UNITS,       # 64\n",
    "                             bidirectional=True, \n",
    "                             batch_first=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features=LSTM_UNITS*2,  # 128\n",
    "                                 out_features=LSTM_UNITS*2  # 128\n",
    "                                )\n",
    "        self.linear2 = nn.Linear(LSTM_UNITS*2,  # 128\n",
    "                                 LSTM_UNITS*2   # 128\n",
    "                                )\n",
    "\n",
    "        self.linear = nn.Linear(LSTM_UNITS*2,   # 128\n",
    "                                n_classes       # 6\n",
    "                               )\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        # x.size() is torch.Size([2, 36, 6144])\n",
    "        h_embedding = x\n",
    "        \n",
    "        n = 2048\n",
    "        # while h_embedding[:,:,:n].size() is torch.Size([2, 36, 2048])\n",
    "        # Selecting and duplicating the first (and origional) of the 3 embeddings (original, lag, lead) \n",
    "        # that were earlier concatted \n",
    "        \n",
    "        # h_embadd.size is torch.Size([2, 36, 4096]), not needed now though\n",
    "        h_embadd = torch.cat((h_embedding[:,:,:n], h_embedding[:,:,:n]), -1)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_lstm1))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_lstm2))\n",
    "        \n",
    "        # SUM the oringal embedding (\"h_embadd\") back to the outputs from the other layers\n",
    "        # \"h_embadd\" had to be used due to doubling of lstm_unit in earlier dimensions (where lstm_unit = 2048)\n",
    "        # However this sum to calculate \"hidden\" then kills my 13GB memory:\n",
    "        hidden = h_lstm1 + h_lstm2 + h_conc_linear1 + h_conc_linear2 + h_embadd\n",
    "\n",
    "        output = self.linear(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try free up some memory\n",
    "del(trnemb, valemb, tstemb)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los function\n",
    "A customer BCEWithLogitsLoss loss function, same as the image classifier loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(data, targets, criterion = torch.nn.BCEWithLogitsLoss()):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    loss_all = criterion(data, targets)\n",
    "    loss_any = criterion(data[:,-1:], targets[:,-1:])\n",
    "    return (loss_all*6 + loss_any*1)/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclaim GPU RAM\n",
    "- context manager to reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\n",
    "- taken from fastai: https://docs.fast.ai/troubleshoot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_mem_restore_ctx():\n",
    "    \" context manager to reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    def __enter__(self): return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if not exc_val: return True\n",
    "        traceback.clear_frames(exc_tb)\n",
    "        raise exc_type(exc_val).with_traceback(exc_tb) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = []\n",
    "# for i in range(10):\n",
    "#     print(1e-4*((0.95*1.0)**(i)))\n",
    "#     ls.append(1e-4*((0.95*1.0)**(i)))\n",
    "    \n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.plot(ls)\n",
    "# plt.xlabel('Epoch number')\n",
    "# plt.ylabel('Learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many epochs are we doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "- Used for retrieving predictions to calculate the validation loss and get the test set predictions\n",
    "- Ignores the mask embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(loader):\n",
    "    valls = []\n",
    "    imgls = []\n",
    "    imgdf = loader.dataset.data.reset_index().set_index('embidx')[['Image']].copy()\n",
    "    for step, batch in enumerate(loader):\n",
    "        inputs = batch[\"emb\"]\n",
    "        mask = batch['mask'].to(device, dtype=torch.int)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        logits = model(inputs)\n",
    "        # get the mask for masked labels\n",
    "        maskidx = mask.view(-1)==1\n",
    "        # reshape for\n",
    "        logits = logits.view(-1, n_classes)[maskidx]\n",
    "        valls.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "        # Get the list of images\n",
    "        embidx = batch[\"embidx\"].detach().cpu().numpy().astype(np.int32)\n",
    "        embidx = embidx.flatten()[embidx.flatten()>-1]\n",
    "        images = imgdf.loc[embidx].Image.tolist() \n",
    "        imgls += images\n",
    "    return np.concatenate(valls, 0), imgls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission to Kaggle\n",
    "Gets the output predictions formatted correctly for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSub(ypred, imgs):\n",
    "    imgls = np.array(imgs).repeat(len(label_cols)) \n",
    "    icdls = pd.Series(label_cols*ypred.shape[0])   \n",
    "    yidx = ['{}_{}'.format(i,j) for i,j in zip(imgls, icdls)]\n",
    "    subdf = pd.DataFrame({'ID' : yidx, 'Label': ypred.flatten()})\n",
    "    return subdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:10:39,282 - Recursion-pytorch - INFO - Create model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "logger.info('Create model')\n",
    "lrgamma = 0.95\n",
    "\n",
    "#LSTM_UNITS = 1024\n",
    "LSTM_UNITS = 2048\n",
    "model = NeuralNet(LSTM_UNITS=LSTM_UNITS, DO = DROPOUT)\n",
    "model = model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "plist = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': DECAY},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = optim.Adam(plist, lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=lrgamma, last_epoch=-1)\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "\n",
    "ypredls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:10:42,198 - Recursion-pytorch - INFO - EPOCH 0\n",
      "2020-01-27 18:10:43,044 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.67631\n",
      "2020-01-27 18:10:49,770 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.10079\n",
      "2020-01-27 18:10:56,523 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.08413\n",
      "2020-01-27 18:11:03,324 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.07459\n",
      "2020-01-27 18:11:10,198 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.07127\n",
      "2020-01-27 18:11:17,022 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.06836\n",
      "2020-01-27 18:11:23,844 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.06579\n",
      "2020-01-27 18:11:30,691 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.06505\n",
      "2020-01-27 18:11:37,489 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.06321\n",
      "2020-01-27 18:11:44,411 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.06199\n",
      "2020-01-27 18:11:51,282 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.06179\n",
      "2020-01-27 18:11:58,017 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.06096\n",
      "2020-01-27 18:12:04,714 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.06059\n",
      "2020-01-27 18:12:11,541 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.06041\n",
      "2020-01-27 18:12:18,253 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.06000\n",
      "2020-01-27 18:12:25,013 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.05957\n",
      "2020-01-27 18:12:31,913 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.05910\n",
      "2020-01-27 18:12:38,616 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.05873\n",
      "2020-01-27 18:12:45,307 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.05829\n",
      "2020-01-27 18:12:52,163 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.05772\n",
      "2020-01-27 18:12:58,963 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.05717\n",
      "2020-01-27 18:13:05,733 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.05665\n",
      "2020-01-27 18:14:28,375 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.05500\n",
      "2020-01-27 18:14:35,263 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.05498\n",
      "2020-01-27 18:14:42,088 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.05480\n",
      "2020-01-27 18:14:48,921 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.05485\n",
      "2020-01-27 18:14:55,705 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.05489\n",
      "2020-01-27 18:15:02,522 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.05455\n",
      "2020-01-27 18:15:09,327 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.05448\n",
      "/home/morgan/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:91: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "2020-01-27 18:15:11,394 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:15:20,980 - Recursion-pytorch - INFO - Epoch 0 val logloss 0.06363 bagged 0.06363\n",
      "2020-01-27 18:15:21,071 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:15:27,252 - Recursion-pytorch - INFO - EPOCH 1\n",
      "2020-01-27 18:15:27,924 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.05417\n",
      "2020-01-27 18:15:34,871 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.04680\n",
      "2020-01-27 18:15:41,812 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.04783\n",
      "2020-01-27 18:15:48,642 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.04817\n",
      "2020-01-27 18:15:55,580 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.04970\n",
      "2020-01-27 18:16:02,484 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.04968\n",
      "2020-01-27 18:16:09,414 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.04990\n",
      "2020-01-27 18:16:16,348 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.05013\n",
      "2020-01-27 18:16:23,252 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.04927\n",
      "2020-01-27 18:16:30,191 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.04846\n",
      "2020-01-27 18:16:37,108 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.04813\n",
      "2020-01-27 18:16:44,043 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.04789\n",
      "2020-01-27 18:16:50,988 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.04826\n",
      "2020-01-27 18:16:57,991 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.04837\n",
      "2020-01-27 18:17:04,910 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.04831\n",
      "2020-01-27 18:17:11,824 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.04822\n",
      "2020-01-27 18:17:18,746 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.04865\n",
      "2020-01-27 18:17:25,727 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.04906\n",
      "2020-01-27 18:17:32,581 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.04874\n",
      "2020-01-27 18:17:39,450 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.04973\n",
      "2020-01-27 18:17:46,420 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.04992\n",
      "2020-01-27 18:17:53,397 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.04970\n",
      "2020-01-27 18:18:00,317 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.04951\n",
      "2020-01-27 18:18:07,243 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.04947\n",
      "2020-01-27 18:18:14,177 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.04966\n",
      "2020-01-27 18:18:21,163 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.04960\n",
      "2020-01-27 18:18:28,119 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.04925\n",
      "2020-01-27 18:18:35,013 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.04932\n",
      "2020-01-27 18:18:42,013 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.04927\n",
      "2020-01-27 18:18:48,977 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.04942\n",
      "2020-01-27 18:18:55,862 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.04968\n",
      "2020-01-27 18:19:02,769 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.04956\n",
      "2020-01-27 18:19:09,723 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.04962\n",
      "2020-01-27 18:19:16,655 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.04979\n",
      "2020-01-27 18:19:23,665 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.04976\n",
      "2020-01-27 18:19:30,537 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.04977\n",
      "2020-01-27 18:19:37,426 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.04991\n",
      "2020-01-27 18:19:44,326 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.04997\n",
      "2020-01-27 18:19:51,286 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.04991\n",
      "2020-01-27 18:19:58,102 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.04969\n",
      "2020-01-27 18:20:00,187 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:20:09,800 - Recursion-pytorch - INFO - Epoch 1 val logloss 0.06619 bagged 0.06332\n",
      "2020-01-27 18:20:09,893 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:20:15,999 - Recursion-pytorch - INFO - EPOCH 2\n",
      "2020-01-27 18:20:16,661 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.05593\n",
      "2020-01-27 18:20:23,663 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.05982\n",
      "2020-01-27 18:20:30,546 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.05657\n",
      "2020-01-27 18:20:37,417 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.05311\n",
      "2020-01-27 18:20:44,339 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.05205\n",
      "2020-01-27 18:20:51,263 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.05066\n",
      "2020-01-27 18:20:58,208 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.05025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:21:05,169 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.04909\n",
      "2020-01-27 18:21:12,139 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.04983\n",
      "2020-01-27 18:21:19,113 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.04931\n",
      "2020-01-27 18:21:26,055 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.04907\n",
      "2020-01-27 18:21:32,960 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.04937\n",
      "2020-01-27 18:21:39,916 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.04928\n",
      "2020-01-27 18:21:46,859 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.04890\n",
      "2020-01-27 18:21:53,774 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.04905\n",
      "2020-01-27 18:22:00,583 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.04910\n",
      "2020-01-27 18:22:07,547 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.04877\n",
      "2020-01-27 18:22:14,489 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.04867\n",
      "2020-01-27 18:22:21,444 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.04862\n",
      "2020-01-27 18:22:28,444 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.04868\n",
      "2020-01-27 18:22:35,280 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.04856\n",
      "2020-01-27 18:22:42,119 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.04812\n",
      "2020-01-27 18:22:48,947 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.04836\n",
      "2020-01-27 18:22:55,822 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.04857\n",
      "2020-01-27 18:23:02,704 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.04864\n",
      "2020-01-27 18:23:09,551 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.04853\n",
      "2020-01-27 18:23:16,415 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.04870\n",
      "2020-01-27 18:23:23,398 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.04863\n",
      "2020-01-27 18:23:30,349 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.04855\n",
      "2020-01-27 18:23:37,237 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.04838\n",
      "2020-01-27 18:23:44,123 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.04820\n",
      "2020-01-27 18:23:50,921 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.04813\n",
      "2020-01-27 18:23:57,799 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.04830\n",
      "2020-01-27 18:24:04,633 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.04805\n",
      "2020-01-27 18:24:11,489 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.04813\n",
      "2020-01-27 18:24:18,285 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.04836\n",
      "2020-01-27 18:24:25,122 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.04832\n",
      "2020-01-27 18:24:31,966 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.04819\n",
      "2020-01-27 18:24:38,895 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.04819\n",
      "2020-01-27 18:24:45,650 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.04811\n",
      "2020-01-27 18:24:47,668 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:24:57,244 - Recursion-pytorch - INFO - Epoch 2 val logloss 0.06626 bagged 0.06327\n",
      "2020-01-27 18:24:57,335 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:25:03,410 - Recursion-pytorch - INFO - EPOCH 3\n",
      "2020-01-27 18:25:04,063 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.07544\n",
      "2020-01-27 18:25:11,081 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.05136\n",
      "2020-01-27 18:25:18,003 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.04740\n",
      "2020-01-27 18:25:24,971 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.04695\n",
      "2020-01-27 18:25:31,882 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.04803\n",
      "2020-01-27 18:25:38,846 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.04682\n",
      "2020-01-27 18:25:45,773 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.04690\n",
      "2020-01-27 18:25:52,637 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.04674\n",
      "2020-01-27 18:25:59,606 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.04676\n",
      "2020-01-27 18:26:06,569 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.04669\n",
      "2020-01-27 18:26:13,442 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.04638\n",
      "2020-01-27 18:26:20,411 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.04599\n",
      "2020-01-27 18:26:27,278 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.04588\n",
      "2020-01-27 18:26:34,244 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.04622\n",
      "2020-01-27 18:26:41,117 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.04627\n",
      "2020-01-27 18:26:47,935 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.04623\n",
      "2020-01-27 18:26:54,742 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.04611\n",
      "2020-01-27 18:27:01,653 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.04616\n",
      "2020-01-27 18:27:08,506 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.04650\n",
      "2020-01-27 18:27:15,412 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.04644\n",
      "2020-01-27 18:27:22,341 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.04690\n",
      "2020-01-27 18:27:29,298 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.04736\n",
      "2020-01-27 18:27:36,170 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.04736\n",
      "2020-01-27 18:27:43,055 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.04709\n",
      "2020-01-27 18:27:49,939 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.04691\n",
      "2020-01-27 18:27:56,960 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.04678\n",
      "2020-01-27 18:28:03,876 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.04671\n",
      "2020-01-27 18:28:10,806 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.04676\n",
      "2020-01-27 18:28:17,731 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.04647\n",
      "2020-01-27 18:28:24,595 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.04646\n",
      "2020-01-27 18:28:31,543 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.04630\n",
      "2020-01-27 18:28:38,453 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.04637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:28:45,401 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.04624\n",
      "2020-01-27 18:28:52,320 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.04625\n",
      "2020-01-27 18:28:59,174 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.04636\n",
      "2020-01-27 18:29:06,092 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.04657\n",
      "2020-01-27 18:29:12,915 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.04662\n",
      "2020-01-27 18:29:19,891 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.04659\n",
      "2020-01-27 18:29:26,913 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.04650\n",
      "2020-01-27 18:29:33,645 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.04653\n",
      "2020-01-27 18:29:35,681 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:29:45,253 - Recursion-pytorch - INFO - Epoch 3 val logloss 0.06401 bagged 0.06296\n",
      "2020-01-27 18:29:45,346 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:29:51,520 - Recursion-pytorch - INFO - EPOCH 4\n",
      "2020-01-27 18:29:52,194 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.10785\n",
      "2020-01-27 18:29:59,239 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.04355\n",
      "2020-01-27 18:30:06,260 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.04139\n",
      "2020-01-27 18:30:13,346 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.04365\n",
      "2020-01-27 18:30:20,312 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.04306\n",
      "2020-01-27 18:30:27,236 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.04212\n",
      "2020-01-27 18:30:34,205 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.04171\n",
      "2020-01-27 18:30:41,213 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.04175\n",
      "2020-01-27 18:30:48,174 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.04185\n",
      "2020-01-27 18:30:55,152 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.04163\n",
      "2020-01-27 18:31:02,056 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.04172\n",
      "2020-01-27 18:31:09,000 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.04251\n",
      "2020-01-27 18:31:15,875 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.04297\n",
      "2020-01-27 18:31:22,843 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.04306\n",
      "2020-01-27 18:31:29,749 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.04374\n",
      "2020-01-27 18:31:36,653 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.04392\n",
      "2020-01-27 18:31:43,530 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.04387\n",
      "2020-01-27 18:31:50,432 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.04386\n",
      "2020-01-27 18:31:57,309 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.04375\n",
      "2020-01-27 18:32:04,246 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.04363\n",
      "2020-01-27 18:32:11,196 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.04387\n",
      "2020-01-27 18:32:18,193 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.04405\n",
      "2020-01-27 18:32:25,192 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.04419\n",
      "2020-01-27 18:32:32,232 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.04420\n",
      "2020-01-27 18:32:39,413 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.04445\n",
      "2020-01-27 18:32:46,475 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.04460\n",
      "2020-01-27 18:32:53,516 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.04465\n",
      "2020-01-27 18:33:00,514 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.04473\n",
      "2020-01-27 18:33:07,523 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.04469\n",
      "2020-01-27 18:33:14,567 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.04480\n",
      "2020-01-27 18:33:21,562 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.04471\n",
      "2020-01-27 18:33:28,650 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.04460\n",
      "2020-01-27 18:33:35,768 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.04451\n",
      "2020-01-27 18:33:42,736 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.04448\n",
      "2020-01-27 18:33:49,691 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.04458\n",
      "2020-01-27 18:33:56,663 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.04448\n",
      "2020-01-27 18:34:03,688 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.04471\n",
      "2020-01-27 18:34:10,692 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.04466\n",
      "2020-01-27 18:34:17,697 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.04458\n",
      "2020-01-27 18:34:24,604 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.04454\n",
      "2020-01-27 18:34:26,626 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:34:36,249 - Recursion-pytorch - INFO - Epoch 4 val logloss 0.06482 bagged 0.06288\n",
      "2020-01-27 18:34:36,341 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:34:42,488 - Recursion-pytorch - INFO - EPOCH 5\n",
      "2020-01-27 18:34:43,135 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.00137\n",
      "2020-01-27 18:34:49,961 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.04327\n",
      "2020-01-27 18:34:57,107 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.04441\n",
      "2020-01-27 18:35:04,159 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.04374\n",
      "2020-01-27 18:35:11,375 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.04175\n",
      "2020-01-27 18:35:18,537 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.04089\n",
      "2020-01-27 18:35:25,650 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.04083\n",
      "2020-01-27 18:35:32,828 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.04156\n",
      "2020-01-27 18:35:40,023 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.04146\n",
      "2020-01-27 18:35:47,088 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.04125\n",
      "2020-01-27 18:35:54,276 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.04128\n",
      "2020-01-27 18:36:01,435 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.04096\n",
      "2020-01-27 18:36:08,481 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.04098\n",
      "2020-01-27 18:36:15,457 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.04122\n",
      "2020-01-27 18:36:22,579 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.04205\n",
      "2020-01-27 18:36:29,697 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.04183\n",
      "2020-01-27 18:36:36,791 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.04159\n",
      "2020-01-27 18:36:43,949 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.04175\n",
      "2020-01-27 18:36:51,054 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.04156\n",
      "2020-01-27 18:36:58,080 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.04182\n",
      "2020-01-27 18:37:05,137 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.04168\n",
      "2020-01-27 18:37:12,184 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.04165\n",
      "2020-01-27 18:37:19,112 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.04162\n",
      "2020-01-27 18:37:26,051 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.04160\n",
      "2020-01-27 18:37:33,114 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.04177\n",
      "2020-01-27 18:37:40,234 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.04167\n",
      "2020-01-27 18:37:47,331 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.04161\n",
      "2020-01-27 18:37:54,396 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.04173\n",
      "2020-01-27 18:38:01,442 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.04184\n",
      "2020-01-27 18:38:08,533 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.04210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:38:15,637 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.04211\n",
      "2020-01-27 18:38:22,712 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.04203\n",
      "2020-01-27 18:38:29,823 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.04200\n",
      "2020-01-27 18:38:36,894 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.04218\n",
      "2020-01-27 18:38:43,918 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.04212\n",
      "2020-01-27 18:38:51,049 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.04220\n",
      "2020-01-27 18:38:58,149 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.04223\n",
      "2020-01-27 18:39:05,195 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.04214\n",
      "2020-01-27 18:39:12,579 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.04216\n",
      "2020-01-27 18:39:19,629 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.04207\n",
      "2020-01-27 18:39:21,651 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:39:31,290 - Recursion-pytorch - INFO - Epoch 5 val logloss 0.06898 bagged 0.06289\n",
      "2020-01-27 18:39:31,383 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:39:37,499 - Recursion-pytorch - INFO - EPOCH 6\n",
      "2020-01-27 18:39:38,147 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.06551\n",
      "2020-01-27 18:39:45,201 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.04076\n",
      "2020-01-27 18:39:52,259 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.03768\n",
      "2020-01-27 18:39:59,230 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.03941\n",
      "2020-01-27 18:40:06,268 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.03928\n",
      "2020-01-27 18:40:13,280 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.03909\n",
      "2020-01-27 18:40:20,264 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.03898\n",
      "2020-01-27 18:40:27,221 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.03857\n",
      "2020-01-27 18:40:34,044 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.03782\n",
      "2020-01-27 18:40:40,994 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.03858\n",
      "2020-01-27 18:40:47,933 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.03849\n",
      "2020-01-27 18:40:54,766 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.03827\n",
      "2020-01-27 18:41:01,747 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.03798\n",
      "2020-01-27 18:41:08,611 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.03836\n",
      "2020-01-27 18:41:15,566 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.03844\n",
      "2020-01-27 18:41:22,450 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.03855\n",
      "2020-01-27 18:41:29,489 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.03845\n",
      "2020-01-27 18:41:36,460 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.03831\n",
      "2020-01-27 18:41:43,511 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.03852\n",
      "2020-01-27 18:41:50,403 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.03824\n",
      "2020-01-27 18:41:57,341 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.03829\n",
      "2020-01-27 18:42:04,310 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.03833\n",
      "2020-01-27 18:42:11,160 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.03823\n",
      "2020-01-27 18:42:18,049 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.03841\n",
      "2020-01-27 18:42:25,074 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.03837\n",
      "2020-01-27 18:42:31,988 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.03830\n",
      "2020-01-27 18:42:38,987 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.03841\n",
      "2020-01-27 18:42:45,896 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.03849\n",
      "2020-01-27 18:42:52,823 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.03838\n",
      "2020-01-27 18:42:59,688 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.03849\n",
      "2020-01-27 18:43:06,691 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.03837\n",
      "2020-01-27 18:43:13,603 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.03839\n",
      "2020-01-27 18:43:20,533 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.03845\n",
      "2020-01-27 18:43:27,531 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.03856\n",
      "2020-01-27 18:43:34,445 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.03861\n",
      "2020-01-27 18:43:41,379 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.03859\n",
      "2020-01-27 18:43:48,372 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.03857\n",
      "2020-01-27 18:43:55,216 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.03854\n",
      "2020-01-27 18:44:02,051 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.03860\n",
      "2020-01-27 18:44:08,907 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.03860\n",
      "2020-01-27 18:44:10,955 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:44:20,551 - Recursion-pytorch - INFO - Epoch 6 val logloss 0.07149 bagged 0.06307\n",
      "2020-01-27 18:44:20,643 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:44:26,751 - Recursion-pytorch - INFO - EPOCH 7\n",
      "2020-01-27 18:44:27,436 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.05759\n",
      "2020-01-27 18:44:34,370 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.03158\n",
      "2020-01-27 18:44:41,340 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.03153\n",
      "2020-01-27 18:44:48,304 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.03251\n",
      "2020-01-27 18:44:55,307 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.03197\n",
      "2020-01-27 18:45:02,296 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.03234\n",
      "2020-01-27 18:45:09,330 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.03242\n",
      "2020-01-27 18:45:16,401 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.03276\n",
      "2020-01-27 18:45:23,366 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.03334\n",
      "2020-01-27 18:45:30,339 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.03338\n",
      "2020-01-27 18:45:37,359 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.03379\n",
      "2020-01-27 18:45:44,329 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.03367\n",
      "2020-01-27 18:45:51,325 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.03418\n",
      "2020-01-27 18:45:58,240 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.03462\n",
      "2020-01-27 18:46:05,158 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.03504\n",
      "2020-01-27 18:46:12,059 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.03512\n",
      "2020-01-27 18:46:19,021 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.03491\n",
      "2020-01-27 18:46:25,957 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.03477\n",
      "2020-01-27 18:46:32,950 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.03494\n",
      "2020-01-27 18:46:39,923 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.03484\n",
      "2020-01-27 18:46:46,812 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.03472\n",
      "2020-01-27 18:46:53,737 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.03484\n",
      "2020-01-27 18:47:00,683 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.03484\n",
      "2020-01-27 18:47:07,618 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.03483\n",
      "2020-01-27 18:47:14,552 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.03485\n",
      "2020-01-27 18:47:21,422 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.03501\n",
      "2020-01-27 18:47:28,370 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.03514\n",
      "2020-01-27 18:47:35,412 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.03510\n",
      "2020-01-27 18:47:42,379 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.03511\n",
      "2020-01-27 18:47:49,282 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.03492\n",
      "2020-01-27 18:47:56,149 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.03491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:48:03,168 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.03478\n",
      "2020-01-27 18:48:10,104 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.03464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:48:16,905 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.03473\n",
      "2020-01-27 18:48:23,795 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.03467\n",
      "2020-01-27 18:48:30,705 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.03452\n",
      "2020-01-27 18:48:37,907 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.03443\n",
      "2020-01-27 18:48:44,992 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.03427\n",
      "2020-01-27 18:48:52,092 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.03432\n",
      "2020-01-27 18:48:59,115 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.03432\n",
      "2020-01-27 18:49:01,153 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:49:10,744 - Recursion-pytorch - INFO - Epoch 7 val logloss 0.07367 bagged 0.06319\n",
      "2020-01-27 18:49:10,841 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:49:17,041 - Recursion-pytorch - INFO - EPOCH 8\n",
      "2020-01-27 18:49:17,715 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.03458\n",
      "2020-01-27 18:49:24,789 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.03188\n",
      "2020-01-27 18:49:31,945 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.03036\n",
      "2020-01-27 18:49:38,982 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.02974\n",
      "2020-01-27 18:49:45,994 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.02808\n",
      "2020-01-27 18:49:53,048 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.02722\n",
      "2020-01-27 18:50:00,072 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.02732\n",
      "2020-01-27 18:50:07,071 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.02780\n",
      "2020-01-27 18:50:14,130 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.02821\n",
      "2020-01-27 18:50:21,181 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.02850\n",
      "2020-01-27 18:50:28,286 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.02879\n",
      "2020-01-27 18:50:35,405 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.02855\n",
      "2020-01-27 18:50:42,505 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.02879\n",
      "2020-01-27 18:50:49,552 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.02872\n",
      "2020-01-27 18:50:56,554 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.02841\n",
      "2020-01-27 18:51:03,597 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.02871\n",
      "2020-01-27 18:51:10,663 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.02863\n",
      "2020-01-27 18:51:17,791 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.02869\n",
      "2020-01-27 18:51:24,872 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.02858\n",
      "2020-01-27 18:51:31,945 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.02863\n",
      "2020-01-27 18:51:39,014 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.02882\n",
      "2020-01-27 18:51:46,003 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.02877\n",
      "2020-01-27 18:51:53,136 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.02865\n",
      "2020-01-27 18:52:00,288 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.02868\n",
      "2020-01-27 18:52:07,334 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.02879\n",
      "2020-01-27 18:52:14,410 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.02881\n",
      "2020-01-27 18:52:21,498 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.02873\n",
      "2020-01-27 18:52:28,655 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.02882\n",
      "2020-01-27 18:52:35,680 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.02896\n",
      "2020-01-27 18:52:42,851 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.02886\n",
      "2020-01-27 18:52:49,867 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.02861\n",
      "2020-01-27 18:52:56,877 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.02862\n",
      "2020-01-27 18:53:03,957 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.02857\n",
      "2020-01-27 18:53:10,994 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.02856\n",
      "2020-01-27 18:53:18,011 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.02871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 18:53:25,159 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.02874\n",
      "2020-01-27 18:53:32,248 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.02877\n",
      "2020-01-27 18:53:39,437 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.02865\n",
      "2020-01-27 18:53:46,578 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.02867\n",
      "2020-01-27 18:53:53,613 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.02862\n",
      "2020-01-27 18:53:55,626 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:54:05,258 - Recursion-pytorch - INFO - Epoch 8 val logloss 0.08200 bagged 0.06319\n",
      "2020-01-27 18:54:05,352 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 18:54:11,508 - Recursion-pytorch - INFO - EPOCH 9\n",
      "2020-01-27 18:54:12,171 - Recursion-pytorch - INFO - Trn step 0 of 1955 trn lossavg 0.02686\n",
      "2020-01-27 18:54:19,194 - Recursion-pytorch - INFO - Trn step 50 of 1955 trn lossavg 0.01849\n",
      "2020-01-27 18:54:26,191 - Recursion-pytorch - INFO - Trn step 100 of 1955 trn lossavg 0.01930\n",
      "2020-01-27 18:54:33,345 - Recursion-pytorch - INFO - Trn step 150 of 1955 trn lossavg 0.01956\n",
      "2020-01-27 18:54:40,421 - Recursion-pytorch - INFO - Trn step 200 of 1955 trn lossavg 0.02027\n",
      "2020-01-27 18:54:47,433 - Recursion-pytorch - INFO - Trn step 250 of 1955 trn lossavg 0.01990\n",
      "2020-01-27 18:54:54,514 - Recursion-pytorch - INFO - Trn step 300 of 1955 trn lossavg 0.02014\n",
      "2020-01-27 18:55:01,530 - Recursion-pytorch - INFO - Trn step 350 of 1955 trn lossavg 0.02088\n",
      "2020-01-27 18:55:08,510 - Recursion-pytorch - INFO - Trn step 400 of 1955 trn lossavg 0.02095\n",
      "2020-01-27 18:55:15,564 - Recursion-pytorch - INFO - Trn step 450 of 1955 trn lossavg 0.02082\n",
      "2020-01-27 18:55:22,616 - Recursion-pytorch - INFO - Trn step 500 of 1955 trn lossavg 0.02072\n",
      "2020-01-27 18:55:29,668 - Recursion-pytorch - INFO - Trn step 550 of 1955 trn lossavg 0.02090\n",
      "2020-01-27 18:55:36,842 - Recursion-pytorch - INFO - Trn step 600 of 1955 trn lossavg 0.02123\n",
      "2020-01-27 18:55:43,917 - Recursion-pytorch - INFO - Trn step 650 of 1955 trn lossavg 0.02165\n",
      "2020-01-27 18:55:50,946 - Recursion-pytorch - INFO - Trn step 700 of 1955 trn lossavg 0.02174\n",
      "2020-01-27 18:55:58,039 - Recursion-pytorch - INFO - Trn step 750 of 1955 trn lossavg 0.02192\n",
      "2020-01-27 18:56:05,191 - Recursion-pytorch - INFO - Trn step 800 of 1955 trn lossavg 0.02211\n",
      "2020-01-27 18:56:12,272 - Recursion-pytorch - INFO - Trn step 850 of 1955 trn lossavg 0.02198\n",
      "2020-01-27 18:56:19,334 - Recursion-pytorch - INFO - Trn step 900 of 1955 trn lossavg 0.02214\n",
      "2020-01-27 18:56:26,401 - Recursion-pytorch - INFO - Trn step 950 of 1955 trn lossavg 0.02194\n",
      "2020-01-27 18:56:33,479 - Recursion-pytorch - INFO - Trn step 1000 of 1955 trn lossavg 0.02199\n",
      "2020-01-27 18:56:40,511 - Recursion-pytorch - INFO - Trn step 1050 of 1955 trn lossavg 0.02201\n",
      "2020-01-27 18:56:47,556 - Recursion-pytorch - INFO - Trn step 1100 of 1955 trn lossavg 0.02207\n",
      "2020-01-27 18:56:54,576 - Recursion-pytorch - INFO - Trn step 1150 of 1955 trn lossavg 0.02197\n",
      "2020-01-27 18:57:01,655 - Recursion-pytorch - INFO - Trn step 1200 of 1955 trn lossavg 0.02202\n",
      "2020-01-27 18:57:08,746 - Recursion-pytorch - INFO - Trn step 1250 of 1955 trn lossavg 0.02202\n",
      "2020-01-27 18:57:15,823 - Recursion-pytorch - INFO - Trn step 1300 of 1955 trn lossavg 0.02210\n",
      "2020-01-27 18:57:22,919 - Recursion-pytorch - INFO - Trn step 1350 of 1955 trn lossavg 0.02203\n",
      "2020-01-27 18:57:29,953 - Recursion-pytorch - INFO - Trn step 1400 of 1955 trn lossavg 0.02199\n",
      "2020-01-27 18:57:36,936 - Recursion-pytorch - INFO - Trn step 1450 of 1955 trn lossavg 0.02204\n",
      "2020-01-27 18:57:44,011 - Recursion-pytorch - INFO - Trn step 1500 of 1955 trn lossavg 0.02205\n",
      "2020-01-27 18:57:50,963 - Recursion-pytorch - INFO - Trn step 1550 of 1955 trn lossavg 0.02208\n",
      "2020-01-27 18:57:57,910 - Recursion-pytorch - INFO - Trn step 1600 of 1955 trn lossavg 0.02205\n",
      "2020-01-27 18:58:05,019 - Recursion-pytorch - INFO - Trn step 1650 of 1955 trn lossavg 0.02212\n",
      "2020-01-27 18:58:11,924 - Recursion-pytorch - INFO - Trn step 1700 of 1955 trn lossavg 0.02214\n",
      "2020-01-27 18:58:18,964 - Recursion-pytorch - INFO - Trn step 1750 of 1955 trn lossavg 0.02220\n",
      "2020-01-27 18:58:26,071 - Recursion-pytorch - INFO - Trn step 1800 of 1955 trn lossavg 0.02217\n",
      "2020-01-27 18:58:33,096 - Recursion-pytorch - INFO - Trn step 1850 of 1955 trn lossavg 0.02231\n",
      "2020-01-27 18:58:40,110 - Recursion-pytorch - INFO - Trn step 1900 of 1955 trn lossavg 0.02237\n",
      "2020-01-27 18:58:47,015 - Recursion-pytorch - INFO - Trn step 1950 of 1955 trn lossavg 0.02249\n",
      "2020-01-27 18:58:49,052 - Recursion-pytorch - INFO - Prep val score...\n",
      "2020-01-27 18:58:58,833 - Recursion-pytorch - INFO - Epoch 9 val logloss 0.09069 bagged 0.06358\n",
      "2020-01-27 18:58:58,927 - Recursion-pytorch - INFO - Prep test sub...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Run Training\n",
    "for epoch in range(EPOCHS):\n",
    "    logger.info(f'EPOCH {epoch}')\n",
    "    tr_loss = 0.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.train()  \n",
    "    for step, batch in enumerate(trnloader):\n",
    "        y = batch['labels'].to(device, dtype=torch.float)\n",
    "        mask = batch['mask'].to(device, dtype=torch.int)\n",
    "        \n",
    "        x = batch['emb'].to(device, dtype=torch.float)\n",
    "        x = torch.autograd.Variable(x, requires_grad=True)\n",
    "        \n",
    "        y = torch.autograd.Variable(y)\n",
    "        logits = model(x).to(device, dtype=torch.float)\n",
    "        \n",
    "        # get the mask for masked labels\n",
    "        maskidx = mask.view(-1)==1\n",
    "        y = y.view(-1, n_classes)[maskidx]\n",
    "        logits = logits.view(-1, n_classes)[maskidx]\n",
    "        # Get loss\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            with gpu_mem_restore_ctx():\n",
    "                scaled_loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%50==0:\n",
    "            logger.info('Trn step {} of {} trn lossavg {:.5f}'. \\\n",
    "                        format(step, len(trnloader), (tr_loss/(1+step))))\n",
    "    \n",
    "        del(batch)\n",
    "        gc.collect()\n",
    "        # Hitting memory errors, possibly with amp\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    output_model_file = os.path.join(WORK_DIR, 'lstm_gepoch{}_lstmepoch{}_fold{}.bin'.format(GLOBALEPOCH, epoch, fold))\n",
    "    torch.save(model.state_dict(), output_model_file)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Get Validation Loss\n",
    "    model.eval()\n",
    "    logger.info('Prep val score...')\n",
    "    ypred, imgval = predict(valloader)\n",
    "    ypredls.append(ypred)\n",
    "     \n",
    "    yvalpred = sum(ypredls[-nbags:])/len(ypredls[-nbags:])\n",
    "    yvalout = makeSub(yvalpred, imgval)\n",
    "    yvalp = makeSub(ypred, imgval)\n",
    "    \n",
    "    # get Val score\n",
    "    weights = ([1, 1, 1, 1, 1, 2] * ypred.shape[0])\n",
    "    yact = valloader.dataset.data[label_cols].values#.flatten()\n",
    "    yact = makeSub(yact, valloader.dataset.data['Image'].tolist())\n",
    "    yact = yact.set_index('ID').loc[yvalout.ID].reset_index()\n",
    "    valloss = log_loss(yact['Label'].values, yvalp['Label'].values.clip(.00001,.99999) , sample_weight = weights)\n",
    "    vallossavg = log_loss(yact['Label'].values, yvalout['Label'].values.clip(.00001,.99999) , sample_weight = weights)\n",
    "    logger.info('Epoch {} val logloss {:.5f} bagged {:.5f}'.format(epoch, valloss, vallossavg))\n",
    "\n",
    "    del(ypred, yvalout, yvalp, imgval, yact)\n",
    "    gc.collect()\n",
    "    \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 21:18:58,318 - Recursion-pytorch - INFO - Prep test sub...\n",
      "2020-01-27 21:19:04,697 - Recursion-pytorch - INFO - Write out bagged prediction to preds folder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "ypredtstls = []\n",
    "model.eval()\n",
    "logger.info('Prep test submission...')\n",
    "ypred, imgtst = predict(tstloader)\n",
    "ypredtstls.append(ypred)\n",
    "\n",
    "logger.info('Write out bagged prediction to preds folder')\n",
    "ytstpred = sum(ypredtstls[-nbags:])/len(ypredtstls[-nbags:])\n",
    "ytstout = makeSub(ytstpred, imgtst)\n",
    "ytstout.ID = [x.split('_', 1)[1] for x in ytstout.ID.values]\n",
    "\n",
    "ytstout.to_csv('preds/mg_lstm_20200127.csv.gz', index = False, compression = 'gzip')\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_9b2d4a7b3_epidural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_9b2d4a7b3_intraparenchymal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_9b2d4a7b3_intraventricular</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_9b2d4a7b3_subarachnoid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_9b2d4a7b3_subdural</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_9b2d4a7b3_any</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label\n",
       "0          ID_9b2d4a7b3_epidural    0.0\n",
       "1  ID_9b2d4a7b3_intraparenchymal    0.0\n",
       "2  ID_9b2d4a7b3_intraventricular    0.0\n",
       "3      ID_9b2d4a7b3_subarachnoid    0.0\n",
       "4          ID_9b2d4a7b3_subdural    0.0\n",
       "5               ID_9b2d4a7b3_any    0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytstout.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv download link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='preds/mg_lstm_20200127.csv.gz' target='_blank'>preds/mg_lstm_20200127.csv.gz</a><br>"
      ],
      "text/plain": [
       "/home/morgan/ml/projects/rsna/rsna_2nd_place_solution/preds/mg_lstm_20200127.csv.gz"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "FileLink('preds/mg_lstm_20200127.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result = 1.29793"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
